# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
DB_HOST=localhost
DB_PORT=5432
DB_NAME=your_database_name
DB_USER=postgres
DB_PASSWORD=your_password

# Legacy (for backward compatibility)
DATABASE_URL=postgresql://postgres:your_password@localhost:5432/your_database_name

# =============================================================================
# EMBEDDING MODEL CONFIGURATION
# =============================================================================
# Embedding provider: 'azure' or 'openai' or 'local'
EMBEDDING_PROVIDER=azure

# Azure OpenAI Settings (if using Azure OpenAI embeddings)
AZURE_OPENAI_API_KEY=your-azure-api-key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-ada-002
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# OpenAI Settings (if using OpenAI embeddings)
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Local Embedding Settings (if using local embeddings)
# Popular models:
# - BAAI/bge-small-en-v1.5 (384 dim, fast, good quality)
# - BAAI/bge-base-en-v1.5 (768 dim, slower, better quality)
# - sentence-transformers/all-MiniLM-L6-v2 (384 dim, very fast)
LOCAL_EMBEDDING_MODEL=BAAI/bge-small-en-v1.5

# =============================================================================
# LLAMA INDEX CONFIGURATION
# =============================================================================
# Text chunking settings
CHUNK_SIZE=1024
CHUNK_OVERLAP=200

# Context window for queries
CONTEXT_WINDOW=3900

# Number of similar documents to retrieve
SIMILARITY_TOP_K=10

# =============================================================================
# PGVECTOR CONFIGURATION
# =============================================================================
# Vector dimension (must match your embedding model)
# - 384 for bge-small, all-MiniLM-L6-v2
# - 768 for bge-base
# - 1536 for OpenAI text-embedding-3-small
VECTOR_DIMENSION=384

# Prefix for vector store tables
VECTOR_TABLE_PREFIX=llamaindex_embedding

# Distance metric: 'cosine', 'l2', or 'inner_product'
VECTOR_DISTANCE_METRIC=cosine

# =============================================================================
# INDEXING CONFIGURATION
# =============================================================================
# Batch size for indexing (lower if memory issues)
INDEX_BATCH_SIZE=100

# Enable incremental indexing (only index new records)
ENABLE_INCREMENTAL_INDEXING=true

# Automatically run migrations on startup
AUTO_RUN_MIGRATIONS=false

# =============================================================================
# CONTENT GENERATION CONFIGURATION
# =============================================================================
# Default LLM provider for content generation: 'openai' or 'local'
LLM_PROVIDER=openai

# OpenAI LLM settings
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=2000

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log file path (leave empty to disable file logging)
LOG_FILE=logs/indexer.log

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
# Application name (used in logs and metadata)
APP_NAME=DigitalGrub Indexer

# Environment: development, staging, production
ENVIRONMENT=development

# Enable debug mode
DEBUG=true
